{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec_Wiki_part1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1oPt-R8uLKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install opencc-python-reimplemented\n",
        "!wget https://dumps.wikimedia.org/zhwiki/20200301/zhwiki-20200301-pages-articles-multistream1.xml-p1p162886.bz2\n",
        "\n",
        "\n",
        "\n",
        "from gensim.corpora import WikiCorpus\n",
        "\n",
        "wiki_corpus = WikiCorpus('zhwiki-20200301-pages-articles-multistream1.xml-p1p162886.bz2', dictionary={})\n",
        "next(iter(wiki_corpus.get_texts()))[:10]\n",
        "\n",
        "text_num = 0\n",
        "\n",
        "with open('wiki_text.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in wiki_corpus.get_texts():\n",
        "        f.write(' '.join(text)+'\\n')\n",
        "        text_num += 1\n",
        "        if text_num % 10000 == 0:\n",
        "            print('{} articles processed.'.format(text_num))\n",
        "\n",
        "    print('{} articles processed.'.format(text_num))\n",
        "\n",
        "import jieba\n",
        "from opencc import OpenCC\n",
        "\n",
        "\n",
        "# Initial\n",
        "cc = OpenCC('s2t')\n",
        "train_data = open('wiki_text.txt', 'r', encoding='utf-8').read()\n",
        "train_data = cc.convert(train_data)\n",
        "train_data = jieba.lcut(train_data)\n",
        "train_data = [word for word in train_data if word != '']\n",
        "train_data = ' '.join(train_data)\n",
        "open('seg.txt', 'w', encoding='utf-8').write(train_data)\n",
        "\n",
        "from gensim.models import word2vec\n",
        "\n",
        "\n",
        "# Settings\n",
        "seed = 666\n",
        "sg = 0\n",
        "window_size = 10\n",
        "vector_size = 100\n",
        "min_count = 1\n",
        "workers = 8\n",
        "epochs = 5\n",
        "batch_words = 10000\n",
        "\n",
        "train_data = word2vec.LineSentence('seg.txt')\n",
        "model = word2vec.Word2Vec(\n",
        "    train_data,\n",
        "    min_count=min_count,\n",
        "    size=vector_size,\n",
        "    workers=workers,\n",
        "    iter=epochs,\n",
        "    window=window_size,\n",
        "    sg=sg,\n",
        "    seed=seed,\n",
        "    batch_words=batch_words\n",
        ")\n",
        "\n",
        "model.save('word2vec.model')\n",
        "\n",
        "\n",
        "from gensim.models import word2vec\n",
        "\n",
        "string = '微生物'\n",
        "model = word2vec.Word2Vec.load('word2vec.model')\n",
        "print(string)\n",
        "\n",
        "for item in model.wv.most_similar(string):\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}